\documentclass{oblivoir}
\usepackage{inputenc, amssymb, amsmath, geometry, hyperref}
\usepackage[utf8]{kotex}

\title{SCSC (SNU Computer Study Club)\\Linear Algebra solution SIG}
\author{lee chan yang, kim jae woo, sin ji hwan, choi seong joon, lim chan yeong}
\date{제작 기간: 23.12.25 $-$ 24.03.01}


\begin{document}
\maketitle
\newpage
\section*{일러두기}
\begin{itemize}
    \item 책은 프리드버그 `5판'을 기준으로 진행 예정 (번역본과 원서의 문제가 다를 경우, 표기 필요.)
    \item 42개의 절 존재. $\rightarrow$ 한 사람당 최소 3개의 절 맡아서 진행. 3개 이상의 절 맡는 것도 가능.
    \item 목표: 제 2의 심지가 되는 것. 이걸 만들고 24년도 심지 칸에 집어넣기를 희망.
    \item 태도: 자신이 공부하는 과정에서 약간의 흔적을 남겨 놓는 수준. $\therefore$ 타 solution의 idea를 가져다 쓰는 것을 허용. 다만 한글로 작성하여 타 solution 과의 차이점을 두고자 함. ($+$ latex 연습)
    \item PIG 돈으로 인쇄해서 현물로 만들어 놓자!
    \item 임찬영: 2.3, 3.2, 5.1
    \item 허유민: 3.3, (4.2 or 4.3), 5.2
    \item 신지환: 1.6, 2.4, 4.3
    \item 이찬양: 2.6, 6.2, 6.3, 6.4, 6.5 (2.6, 6.4, 6.5 우선)
    \item 최성준: 6.8, 6.9, 6.10, 6.11
    \item 최호석: 7.1, 7.2, 7.3, 7.4 
    \item 김재우: ㅈ
    \item 김지훈:

\end{itemize}


\newpage
\tableofcontents



\newpage
\section{벡터공간}
\subsection{개론}
\subsection{벡터공간}
\subsection{부분공간}
\subsection{일차결합과 연립일차방정식}
\subsection{일차종속과 일차독립}
\subsection{기저와 차원}
\subsection{일차독립인 극대 부분집합*}

\newpage
\section{선형변환과 행렬}
\subsection{선형변환, 영공간, 상공간}
\subsection{선형변환의 행렬표현}
\subsection{선형변환의 합성과 행렬 곱}
\subsection{가역성과 동형사상}
\subsection{좌표변환 행렬}
\subsection{쌍대공간*}

\begin{enumerate}
    \item 
    \begin{enumerate}
        \item False. 반례: linear transformation $T:{\mathbb{R}}^2 \rightarrow {\mathbb{R}}^2$ 는 linear functional이 아니다. (다만, 모든 linear functional은 linear transformation이다.)
        \item True. 임의의 ${V}^*$는 $\mathcal{L}(\mathbb{F}, \mathbb{F})$로 정의되고, 이는 $M_{1\times n}(\mathbb{F})$와 isomorphic하다. 따라서 체 $\mathbb{F}$ 위에서 정의된 linear function은 $\mathcal{L}(\mathbb{F}, \mathbb{F})$의 원소이고, 이는 $M_{1\times 1}(\mathbb{F})$와 isomorphic하므로 $1\times1$ matrix로 나타낼 수 있다.
        \item True. \\
        $\because$ 임의의 n차원 벡터공간 $V$에 대하여, 
        \begin{equation}
            \dim(V^*) = \dim(\mathcal{L}(V, \mathbb{F})) = \dim(\mathcal{L}) \times \dim(\mathbb{F}) = \dim(\mathcal{L}) \times 1 = \dim(V)            
        \end{equation}
        이므로 Thm x.x 에 의해 벡터공간인 $V$의 dual space, $V^*$와 원래 주어진 $V$와 isomorphic하다.
        \item True. 임의의 vector space $V$에 대하여 $\dim(V) = \dim(V^{**}) = \dim({({V^*})}^*)$이다. 물론 (같은 field $\mathbb{F}$ 위에서 정의된) $\dim(V)$차원의 벡터 공간 $\mathbb{W}$를 가져와도, $\dim(V) = \dim(W) = \dim(W^*)$이므로 조건을 만족한다.
        \item False.
        \item 추가 예정
        \item True. $\because$ they have same dimension.
        \item 추가 예정
    \end{enumerate}
    
    \item %2
        \begin{enumerate}
            \item 해당 $f$는 $f\colon V \to R$이다. (1)\\
            $f(A+c\cdot g(x)) = f(p(x)) + c\cdot f(g(x))$ for all $p, f \in V, c \in R$임을 보이자. \\
            $(LHS) = 2(p+cg)'(0)+(p+cg)''(1) \stackrel{def}{=} 2(p'(0)+cg'(0)) + p''(1) + cg''(1) = (2p'(0)+p''(1)) + c(2g'(0) + g''(1)) = (RHS)$           
            이므로 $f$는 linear하다. (2)\\
            따라서 (1)과 (2)에 의해 $f$는 linear functional이다.
            \item 해당 $f$는 $f\colon V\to V$, 즉 field $R$을 codomain으로 가지지 않기 때문에 linear            functional이 아니다.
            \item 해당 $f$는 $f\colon V \to F$이다. (1)\\
            $f(A+cB) = f(A) + c\cdot f(B)$ for all $A, B \in V, c \in F$임을 보이자. $(LHS) = f(A+cB) = tr(A+cB) = \displaystyle{\sum_{i=1}^{2} {{(A+cB)}_{ii}}} = \sum_{i=1}^{2}(A_{ii} + cB_{ii}) = \sum_{i=1}^{2}A_{ii} + \sum_{i=1}^{2}(cB_{ii}) = tr(A) + tr(cB) = (RHS)$ 이므로 f는 linear하다. (2)\\
            따라서 (1)과 (2)에 의해 f는 linear functional이다.
            \item 해당 $f$는 $f\colon V \to R$이다. (1)\\
            반례: $f$가 linear하다면 $f(-2,0, 1) = f(-1, 0, 1) + f(-1, 0, 1)$이어야 한다. 그러나 $(LHS) = {(-2)}^{2} + {0}^{2} + {1}^{2} = 5$, $(RHS) = 2 + 2 = 4$, 즉 $(LHS) \neq (RHS)$이다. 즉 $f$는 linear하지 않다. (2)\\
            따라서 (2)에 의해 $f$는 linear functional이 아니다.
            \item 
        \end{enumerate}
    \item 
    \item\hypertarget{2.6_4}{} $\beta^*=\{{\textbf{f}}_{1}, {\textbf{f}}_{2}, {\textbf{f}}_{3}\}$가 basis임을 보이기 위해 linearly independent 혹은 $span{\beta}^* = V^*$ 임을 보이기보다, 해당 $\textbf{f}_i$들이 $\textbf{f}_i(\mathbf{x}_j)=\delta _{ij}$를 만족할 수 있도록 하는 $\mathbf{x}_j \in V$들을 찾고, 이 $\mathbf{x}_j$들을 원소로 하는 집합 $\beta=\{\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\}$가 ${\mathbb{R}}^3$의 기저임을 보이면 thm 2.24에 의해 $\beta^*$는 기저가 됨을 이용하자.\\
    $\beta = \{\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\}$라 하자. $\mathbf{x}_1 = (x_1, y_1, z_1), \cdots$라 하자. 
    \begin{align}
        \textbf{f}_1(x_1, y_1, z_1) = 1 \text{ and } \textbf{f}_1(x_2, y_2, z_2) = 0 \text{ and } \textbf{f}_1(x_3, y_3, z_3) = 0 \\
        \textbf{f}_2(x_1, y_1, z_1) = 0 \text{ and } \textbf{f}_2(x_2, y_2, z_2) = 1 \text{ and } \textbf{f}_2(x_3, y_3, z_3) = 0 \\
        \textbf{f}_3(x_1, y_1, z_1) = 0 \text{ and } \textbf{f}_3(x_2, y_2, z_2) = 0 \text{ and } \textbf{f}_3(x_3, y_3, z_3) = 1 \\
    \end{align}
    \begin{align}
        \Longleftrightarrow
        \begin{pmatrix}
            1 & -2 & 0\\
            1 & 1 & 1\\
            0 & 1 & -3
        \end{pmatrix}
        \begin{pmatrix}
            \mid & \mid & \mid\\
            \mathbf{x}_1 & \mathbf{x}_2 & \mathbf{x}_3\\
            \mid & \mid & \mid
        \end{pmatrix}
        =
        \begin{pmatrix}
            1 & 0 & 0\\
            0 & 1 & 0\\
            0 & 0 & 1
        \end{pmatrix}\\
        \Longrightarrow
        \begin{pmatrix}
            \mid & \mid & \mid\\
            \mathbf{x}_1 & \mathbf{x}_2 & \mathbf{x}_3\\
            \mid & \mid & \mid
        \end{pmatrix}
        =
        \begin{pmatrix}
            1 & -2 & 0\\
            1 & 1 & 1\\
            0 & 1 & -3
        \end{pmatrix}^{-1}
        =
        \begin{pmatrix}
            2/5 & 3/5 & 1/5\\
            -3/5 & 3/10 & 1/10\\
            -1/10 & 1/10 & -3/10
        \end{pmatrix}
    \end{align}
    
    \item \hyperlink{2.6_4}{4번의 solution} 과 풀이 과정 유사
    \item \hypertarget{2.6_6}{}
    \begin{enumerate}
        \item Thm 2.25의 정의에 의해 $T^t(f) := f\circ T$이므로 $T^t(f)(x,\ y) = (f\circ T)(x,\ y)$를 구하자. \\
        $f\circ T(x,\ y) = f(3x+2y,\ x) = 7x+4y$이다.
        \item $V=\mathbb{R}^2$의 표준순서기저 $\beta = \{(1, 0), (0, 1)\}$에 대해 다음 system을 만족하는 $f_1,\ f_2$를 찾자.
        \(\begin{cases}
            x + 2y = 1\\ 2x-y = 4
        \end{cases}\)
        \begin{equation}\begin{cases}
            f_1(e_1) = 1,\ f_1(e_2)=0\\
            f_2(e_1) = 0,\ f_2(e_2)=1
        \end{cases}
        \end{equation}
        따라서 $f_1(x,\ y)=x,\ f_2(x,\ y)=y$이다. 따라서 
        \begin{equation}\begin{cases}
            T^t(f_1)(x,\ y) = (f_1\circ T)(x,\ y) = f_1(3x+2y,\ x) = 3x+2y = 3f_1(x,\ y) + 2f_2(x,\ y)\\
            T^t(f_2)(x,\ y) = (f_2\circ T)(x,\ y) = f_2(3x+2y,\ x) = x = 1f_1(x,\ y) + 0f_2(x,\ y)
        \end{cases}\end{equation}
        $\therefore{[T^t]}_{\beta^*}=
        \begin{pmatrix}
            3 & 1\\
            2 & 0
        \end{pmatrix}$이다.
        \item $T(e_1) = (3,\ 1)\ and\ T(e_2) = (2,\ 0) \Rightarrow {[T]}_{\beta^*}$ = 
        $\begin{pmatrix}
            3 & 2\\
            1 & 0
        \end{pmatrix}$
        $\Rightarrow {({[T]}_{\beta^*})}^t$ = 
        $\begin{pmatrix}
            3 & 1\\
            2 & 0
        \end{pmatrix}$이다.
    \end{enumerate}
    \item \hyperlink{2.6_6}{6번의 solution} 과 풀이 과정 유사
    \item 임의의 \(f \in \mathcal{L}(\mathbb{R}^3, \mathbb{R})\)는 \(f(x, y, z) = ax+by+cz\)로 표현할 수 있다.
    \item 
    \item \dots
    \item \dots 
    \item \dots
    \item 
    \begin{enumerate}
    \item closed in addition, scalar multiplication, including zero vector 를 보이면 됨.
    \item 자세한 사항은 la sol 보고 이해했음. W의 기저들로 이루어지는 벡터들은 모두 0으로 보내는 함수이지만 문제에서의 x를 기저로 가지는, 혹은 x와 평행하게 scaling 되는 벡터는 0이 아닌 (ex. 1) 값을 가지게 되는 f 하나 찾으면 됨. 이는 linear functional이 되기 떄문에 해당 조건을 만족하는 f가 존재함을 확인할 수 있음.
    \end{enumerate}
\end{enumerate}




\subsection{계수가 상수인 동차 선형 미분방정식*}

\newpage
\section{기본행렬연산과 연립일차방정식}
\subsection{기본행렬연산과 기본행렬}
\subsection{행렬의 랭크와 역행렬}
\subsection{연립일차방정식 : 이론적 측면}
\subsection{연립일차방정식 : 계산적 측면}

\newpage
\section{행렬식}
\subsection{2차 정사각행렬의 행렬식}
\subsection{n차 정사각행렬의 행렬식}
\subsection{행렬식의 성질}
\subsection{행렬식의 핵심 요약}
\subsection{행렬식의 엄밀한 정의*}

\newpage
\section{대각화}
\subsection{고윳값과 고유벡터}
\subsection{대각화 가능성}
\subsection{행렬의 극한과 마르코프 연쇄*}
\subsection{불변 부분공간과 케일리-해밀턴 정리}

\newpage
\section{내적공간}
\subsection{내적과 노름}
\subsection{그람-슈미트 직교화와 직교여공간}
\subsection{선형연산자의 수반연산자}
\begin{enumerate}
    \item 
    \item 
    \item
    \begin{enumerate}
        \item \(T^*\)는 임의의 orthonormal basis \(\gamma\)를 잡아도 T에 의해 유일하게 결정된다. 따라서 
        \begin{align*} \forall(x, y)\in V(=\mathbb{R}^2)\quad\left\langle (x, y),\,(\alpha,\beta) \right\rangle = \left\langle (x, y), \,T^*(3 ,5)\right\rangle \end{align*}
        를 만족하는 \(T^*(3 ,5)\)가 유일하게 존재한다. 따라서
        \begin{equation*}\begin{split}
            \left\langle (x, y), \,T^*(3, 5)\right\rangle & = \left\langle T(x, y),\, (3, 5)\right\rangle \\
            &= \left\langle(2x+y, x-3y), \, (3, 5) \right\rangle\\
            & = 11x-12y = \left\langle (x, y), \, (11, -12)\right\rangle
        \end{split}\end{equation*}
        이므로 Thm 6.1(5)에 의해 \(T^*(3, 5)=(11, -12)\)이다.
        \item 
        \item 
    \end{enumerate}
    \item 
    \item 
\end{enumerate}
\subsection{정규연산자와 자기수반연산자}
\begin{enumerate}
    \item 
    \begin{enumerate}
        \item True. \(TT^* = T^2 = T^*T\)이므로 모든 self-adjoint는 항상 normal operator이다.
        \item False.\ self-adjoint는 field \(\mathbb{C}\)에서 항상 real value로 고윳값을 가지는 반면, 일반 operator는 complex value로 고윳값을 가질 수 있다.\\ (+ 원서 4, 5판의 경우, 번역본과 달리 '고유벡터가 같다'의 명제로 묻는다. 이 또한 당연히 다르며, \(\begin{pmatrix} 1&1\\0&1\end{pmatrix}\)과 \(\begin{pmatrix} 1&0\\1&1\end{pmatrix}\)이 그 예이다. 이때 고유벡터를 sclaing 해도 고유벡터이므로, normalization한 각 고유벡터끼리 비교해도 다르다.)
        \item False. \(T:{\mathbb{R}}^2\rightarrow{\mathbb{R}}^2\)를 원점을 기준으로 하여 반시계방향으로 \(\theta\)만큼 회전하는 선형변환이라 하자. \(TT^*=T^*T=I\)이므로 T는 normal operator이다. 이때 \(\mathbb{R}^2\)의 기저를 orthogonal하지 않도록 \(\beta=\{(1, 0). (\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})\}\)로 잡자. 그러면 아래와 같이 \[[T]_\beta = \begin{pmatrix} \cos\theta-\sin\theta&\cos(\theta+\frac{\pi}{4})-\sin(\theta+\frac{\pi}{4})\\\sqrt{2}\sin\theta&\sqrt{2}\sin(\theta+\frac{\pi}{4})\end{pmatrix}\]이고, 불필요한 계산을 줄이기 위해 1행 1열의 원소만 확인하면 \(([T]_\beta[T]^*_\beta)_{11} = \frac{-\sqrt{2}\cos(2\theta)+\cos(2\theta)-\sqrt{2}\sin(2\theta)-\sin(2\theta)-\sqrt{2}+4}{2}\)이고, \({([T]^*_\beta[T]_\beta)}_{11}=-\cos(2\theta)-\sin(2\theta)+2\)이므로 \([T]_\beta[T]^*_\beta \neq [T]^*_\beta[T]_\beta\)임을 확인할 수 있다.
        \item 
        \item 
        \item 
    \end{enumerate}
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
\end{enumerate}


\subsection{연산자와 행렬 : 유니타리 연산자와 직교연산자}
\subsection{정사영과 스펙트럼 정리}
\subsection{특잇값 분해와 유사역행렬*}
\subsection{쌍선형과 이차형식*}
\subsection{아인슈타인의 특수상대성 이론*}
\subsection{ 조건화와 레일리 몫*}
\subsection{ 직교연산자와 기하학*}

\newpage
\section{표준형}
\subsection{조르당 표준형 I : 이론적 측면}
\subsection{조르당 표준형 II : 계산적 측면}
\subsection{최소다항식}
\subsection{유리 표준형*}









\end{document}